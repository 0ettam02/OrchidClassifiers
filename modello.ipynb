{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splittato con successo!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#PERCORSO DATASET\n",
    "dataset_dir = \"dataset_orchidee\"\n",
    "output_dir = \"dataset_split\"\n",
    "\n",
    "#DATI DA USARE PER IL TEST\n",
    "test_size = 0.3\n",
    "\n",
    "# Creazione delle directory di output\n",
    "for split in [\"train\", \"test\"]:\n",
    "    os.makedirs(os.path.join(output_dir, split), exist_ok=True)\n",
    "\n",
    "# Itera su tutte le classi (sottodirectory di dataset_dir)\n",
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_path = os.path.join(dataset_dir, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue  \n",
    "\n",
    "    # Creazione delle directory di output per ogni classe\n",
    "    train_class_dir = os.path.join(output_dir, \"train\", class_name)\n",
    "    test_class_dir = os.path.join(output_dir, \"test\", class_name)\n",
    "    os.makedirs(train_class_dir, exist_ok=True)\n",
    "    os.makedirs(test_class_dir, exist_ok=True)\n",
    "\n",
    "    # Lista dei file per la classe corrente\n",
    "    files = os.listdir(class_path)\n",
    "    \n",
    "    # Divisione in train e test\n",
    "    train_files, test_files = train_test_split(files, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Copia dei file nella directory corrispondente\n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(class_path, file), os.path.join(train_class_dir, file))\n",
    "    for file in test_files:\n",
    "        shutil.copy(os.path.join(class_path, file), os.path.join(test_class_dir, file))\n",
    "\n",
    "print(\"Dataset splittato con successo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import dataloader\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.RandomHorizontalFlip(),  \n",
    "#     transforms.RandomVerticalFlip(),\n",
    "#     transforms.RandomRotation(20),      \n",
    "#     transforms.RandomResizedCrop(224), \n",
    "#     transforms.ToTensor(),\n",
    "#     #QUESTI SONO I VALORI MEDI PER IL MODELLO MOBILENET \n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# ])\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.ToImage(),  \n",
    "    v2.Resize(256),\n",
    "    v2.RandomHorizontalFlip(),  \n",
    "    v2.RandomVerticalFlip(),\n",
    "    v2.RandomRotation(20),    \n",
    "    v2.RandomPerspective(),\n",
    "    v2.ToDtype(torch.uint8, scale=True), \n",
    "    v2.RandomResizedCrop(size=(224, 224), antialias=True),  \n",
    "    v2.ToDtype(torch.float32, scale=True),  \n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#DATASET\n",
    "train_dataset = datasets.ImageFolder('dataset_split/train', transform=v2)\n",
    "test_dataset = datasets.ImageFolder('dataset_split/test', transform=v2)\n",
    "\n",
    "#DATALOADER\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETE MOBILENET PREADDESTRATA\n",
    "mobilenet = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "\n",
    "#CONGELAMENTO DEI PESI DEL FEAUTURE EXTRACTOR\n",
    "for param in mobilenet.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#NUMERO TOTALE DELLE CLASSI\n",
    "dataset_dir = \"dataset\"\n",
    "num_classes = len(os.listdir(dataset_dir))\n",
    "\n",
    "\n",
    "#MODIFICA DEL CLASSIFICATORE PER RENDERLO MULTICLASSE\n",
    "num_features = mobilenet.last_channel\n",
    "mobilenet.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.4),               \n",
    "    nn.Linear(num_features, 256),  \n",
    "    nn.ReLU(),                     \n",
    "    nn.Dropout(0.4),               \n",
    "    nn.Linear(256, 128),          \n",
    "    nn.ReLU(),                     \n",
    "    nn.Linear(128, num_classes),   \n",
    "    nn.LogSoftmax(dim=1)           \n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
